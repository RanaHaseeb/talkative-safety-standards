<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Talkative — Child Safety & Protection Policy</title>
  <meta name="description" content="Talkative's published standards for preventing child sexual abuse and exploitation (CSAE) and how to report concerns." />
  <style>
    :root{--bg:#f7fafc;--card:#ffffff;--accent:#5b21b6;--muted:#6b7280}
    body{font-family:Inter, system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial; background:var(--bg); color:#111827; margin:0; padding:32px}
    .container{max-width:900px;margin:0 auto}
    header{display:flex;align-items:center;gap:16px}
    .logo{width:58px;height:58px;border-radius:12px;background:linear-gradient(135deg,#7c3aed,#06b6d4);display:flex;align-items:center;justify-content:center;color:white;font-weight:700}
    .card{background:var(--card);border-radius:12px;padding:24px;box-shadow:0 6px 18px rgba(15,23,42,0.06);margin-top:20px}
    h1{margin:0;font-size:22px}
    h2{font-size:18px;margin-top:20px}
    p{line-height:1.5;color:#111827}
    ul{margin:8px 0 16px 20px}
    .muted{color:var(--muted)}
    .contact{display:flex;flex-direction:column;gap:6px}
    .report-box{background:#fff7ed;border-left:4px solid #f97316;padding:12px;border-radius:8px}
    a.button{display:inline-block;padding:10px 14px;border-radius:8px;background:var(--accent);color:#fff;text-decoration:none}
    footer{margin-top:26px;color:var(--muted);font-size:13px}
    code{background:#f3f4f6;padding:2px 6px;border-radius:6px;font-size:13px}
  </style>
</head>
<body>
  <div class="container">
    <header>
      <div class="logo">T</div>
      <div>
        <h1>Talkative — Child Safety & Protection Policy</h1>
        <div class="muted">Last updated: September 20, 2025</div>
      </div>
    </header>

    <div class="card">
      <h2>Overview</h2>
      <p>
        Talkative is committed to the safety of children and takes a zero-tolerance approach to child sexual abuse material (CSAM), sexual exploitation, grooming, and any other form of sexual or physical harm involving minors. This page describes our published standards, reporting channels, moderation and prevention practices, and our cooperation with law enforcement and relevant authorities.
      </p>

      <h2>Published Safety Standards (CSAE)</h2>
      <p>Our publicly published standards against child sexual abuse and exploitation include the following commitments and practices:</p>
      <ul>
        <li><strong>Zero tolerance:</strong> We prohibit any CSAM, sexual exploitation, grooming, or sexual solicitations involving minors.</li>
        <li><strong>Clear reporting mechanisms:</strong> Users can report suspected CSAM or grooming directly in-app using the "Report" button available on chats and profiles.</li>
        <li><strong>Rapid response:</strong> Reports alleging CSAE are prioritized for immediate review by our safety team.</li>
        <li><strong>Escalation to authorities:</strong> When a report indicates potential illegal activity or CSAM, we preserve evidence and report to regional/national law enforcement and/or relevant hotlines as required by law.</li>
        <li><strong>Account actions:</strong> We may suspend or permanently ban accounts implicated in CSAE, and remove content that violates these standards.</li>
        <li><strong>Age gating & guidance:</strong> Our app is intended for users aged 18+. We publish clear age recommendations and guidance in app descriptions and onboarding flows. (Adjust this to your actual age policy if different.)</li>
        <li><strong>Moderation tools:</strong> A mix of automated systems and human reviewers are used to detect and remove CSAM and suspicious behavior, including keyword filters, image screening, and rate-limit protections.</li>
        <li><strong>Data retention & preservation:</strong> We retain relevant content and metadata for a defined period to support investigations and legal requests, in line with our Privacy Policy and applicable law.</li>
        <li><strong>Privacy & user rights:</strong> We balance user privacy with legal obligations; we only disclose user data to authorities when required by law or in response to valid legal requests.</li>
        <li><strong>Training & reviews:</strong> Our moderation teams receive regular training on CSAE indicators and legal obligations; we review policies periodically to stay current with law and platform requirements.</li>
      </ul>

      <h2>How to Report Concerns</h2>
      <div class="report-box">
        <p><strong>In-app reporting (recommended):</strong> Open the chat or user profile, tap <em>Report</em>, choose a reason (e.g., "Sexual content involving a minor"), and submit. Provide as much detail as possible. Our team will review and act.</p>
      </div>

      <p>
        <strong>Other ways to contact us:</strong>
      </p>
      <div class="contact">
        <div>Email (designated developer contact): <a href="mailto:ranahaseeb33@gmail.com">ranahaseeb33@gmail.com</a></div>
        <div>If you prefer to use a web form for non-urgent feedback, please email us and we will provide an intake link.</div>
      </div>

      <h2>What happens after you report</h2>
      <ul>
        <li>Immediate triage to assess urgency and potential illegality.</li>
        <li>Preservation of relevant content (messages, images, metadata) for investigation and potential law enforcement requests.</li>
        <li>Account action (temporary suspension, permanent ban) where policy violations are found.</li>
        <li>Referral to law enforcement or child protection authorities when required.</li>
      </ul>

      <h2>Cooperation with Authorities</h2>
      <p>
        We comply with applicable laws and cooperate with regional, national, and international law enforcement and child protection agencies. If a report suggests criminal activity or CSAM, we will disclose account data and preserved content in response to valid legal requests, subpoenas, or emergency disclosure provisions.
      </p>

      <h2>Prevention & Safety-by-Design</h2>
      <ul>
        <li>Anonymous usernames are generated on load, but linking to third-party accounts (e.g., Gmail) is optional and requires explicit user consent.</li>
        <li>Rate limits, content filters, and behavioral heuristics are used to detect suspicious accounts or patterns indicative of grooming or exploitation.</li>
        <li>We provide in-app education and safety tips for users about how to stay safe and how to report concerning behavior.</li>
      </ul>

      <h2>Related Policies & Links</h2>
      <ul>
        <li><a href="https://www.privacypolicies.com/live/458aed5d-cb4a-49d0-a295-39db0ae331ef">Privacy Policy</a></li>
        <li><a href="https://ranahaseeb.github.io/talkative-safety-standards/terms-of-service.html">Terms of Service</a></em></li>
        <li>Google Play Help: Reporting child sexual abuse content — see Play Console Help for developers.</li>
      </ul>

      <h2>Contact & Responsible Point of Contact</h2>
      <p>
        The designated point of contact for questions about CSAM prevention and compliance is the developer contact associated with this Play Console account:
      </p>
      <p><strong>Email:</strong> <a href="mailto:ranahaseeb33@gmail.com">ranahaseeb33@gmail.com</a></p>

      <h2>Commitment to Continuous Improvement</h2>
      <p>
        We review this policy regularly and update our technical measures, moderation practices, and reporting workflows to remain aligned with best practices, legal obligations, and platform requirements.
      </p>

      <footer>
        <div class="muted">If you are a child in immediate danger, please contact your local emergency services right away. This page is for published safety standards and reporting; it does not replace urgent emergency assistance.</div>
      </footer>
    </div>
  </div>
</body>
</html>
